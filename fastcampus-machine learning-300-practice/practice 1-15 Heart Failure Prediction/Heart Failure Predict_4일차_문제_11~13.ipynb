{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "매일 조금씩 4일차  문제 11~13",
      "provenance": [],
      "collapsed_sections": [
        "ODJVmYvIP3x-",
        "cxZwPnfms0-9"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeeJeaHyuk/colab/blob/main/%EB%A7%A4%EC%9D%BC_%EC%A1%B0%EA%B8%88%EC%94%A9_4%EC%9D%BC%EC%B0%A8_%EB%AC%B8%EC%A0%9C_11~13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqqLNJZjfi8U"
      },
      "source": [
        "# 주제 : 데이터 분석으로 심부전증을 예방할 수 있을까?\n",
        "----------\n",
        "\n",
        "## 실습 가이드\n",
        "    1. 데이터를 다운로드하여 Colab에 불러옵니다.\n",
        "    2. 필요한 라이브러리는 모두 코드로 작성되어 있습니다.\n",
        "    3. 코드는 위에서부터 아래로 순서대로 실행합니다.\n",
        "    \n",
        "    \n",
        "## 데이터 소개\n",
        "    - 이번 주제는 Heart Failure Prediction 데이터셋을 사용합니다.\n",
        "    \n",
        "    - 다음 1개의 csv 파일을 사용합니다.\n",
        "    heart_failure_clinical_records_dataset.csv\n",
        "    \n",
        "    - 각 파일의 컬럼은 아래와 같습니다.\n",
        "    age: 환자의 나이\n",
        "    anaemia: 환자의 빈혈증 여부 (0: 정상, 1: 빈혈)\n",
        "    creatinine_phosphokinase: 크레아틴키나제 검사 결과\n",
        "    diabetes: 당뇨병 여부 (0: 정상, 1: 당뇨)\n",
        "    ejection_fraction: 박출계수 (%)\n",
        "    high_blood_pressure: 고혈압 여부 (0: 정상, 1: 고혈압)\n",
        "    platelets: 혈소판 수 (kiloplatelets/mL)\n",
        "    serum_creatinine: 혈중 크레아틴 레벨 (mg/dL)\n",
        "    serum_sodium: 혈중 나트륨 레벨 (mEq/L)\n",
        "    sex: 성별 (0: 여성, 1: 남성)\n",
        "    smoking: 흡연 여부 (0: 비흡연, 1: 흡연)\n",
        "    time: 관찰 기간 (일)\n",
        "    DEATH_EVENT: 사망 여부 (0: 생존, 1: 사망)\n",
        "    \n",
        "    \n",
        "    \n",
        "- 데이터 출처: https://www.kaggle.com/andrewmvd/heart-failure-clinical-data\n",
        "\n",
        "\n",
        "## 최종 목표\n",
        "    - 의료 데이터와 그 분석에 대한 이해\n",
        "    - Colab 및 Pandas 라이브러리 사용법 이해\n",
        "    - 데이터 시각화를 통한 인사이트 습득 방법의 이해\n",
        "    - Scikit-learn 기반의 모델 학습 방법 습득\n",
        "    - Classification 모델의 학습과 평가 방법 이해\n",
        "\n",
        "- 출제자 : 신제용 강사\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODJVmYvIP3x-"
      },
      "source": [
        "## Step 0. 의료 데이터셋에 대하여"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0iKTnLNsraM"
      },
      "source": [
        "### 의료 데이터의 수집\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxZwPnfms0-9"
      },
      "source": [
        "### 의료 데이터 분석의 현재\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEcB6i1os0y_"
      },
      "source": [
        "### Accuracy, Precision, 그리고 Recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRssoNrgP7So"
      },
      "source": [
        "## Step 1. 데이터셋 준비하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g49RuFGrBvt7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paInbv8Ys-Qy"
      },
      "source": [
        "### 문제 1. Colab Notebook에 Kaggle API 세팅하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRXGYV60B7FX"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMKFOC0OBtHO"
      },
      "source": [
        "# os.environ을 이용하여 Kaggle API Username, Key 세팅하기\n",
        "os.environ['KAGGLE_USERNAME'] ='leejeahyuk'\n",
        "os.environ['KAGGLE_KEY'] ='909dc28f843ffc03b80b5291757fd8f0'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvbeoB_WtBi-"
      },
      "source": [
        "### 문제 2. 데이터 다운로드 및 압축 해제하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSblp2NsCGbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b38a68d3-74f5-494d-e417-d0a1c180f1eb"
      },
      "source": [
        "# Linux 명령어로 Kaggle API를 이용하여 데이터셋 다운로드하기 (!kaggle ~)\n",
        "# Linux 명령어로 압축 해제하기\n",
        "!kaggle datasets download -d andrewmvd/heart-failure-clinical-data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heart-failure-clinical-data.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '*.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKJrE2tbGUIo",
        "outputId": "46feedf6-3c9e-46cf-b2c9-47ccf933f919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  heart-failure-clinical-data.zip\n",
            "replace heart_failure_clinical_records_dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
            "error:  invalid response [{ENTER}]\n",
            "replace heart_failure_clinical_records_dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-MvGqNeGNxw",
        "outputId": "3ff1593a-c26f-4e62-bef2-94818ca4b3b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heart-failure-clinical-data.zip\t\t    sample_data\n",
            "heart_failure_clinical_records_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ34SovLtFI8"
      },
      "source": [
        "### 문제 3. Pandas 라이브러리로 csv파일 읽어들이기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnJv-4YwCMSx"
      },
      "source": [
        "# pd.read_csv()로 csv파일 읽어들이기\n",
        "df = pd.read_csv('heart_failure_clinical_records_dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L3BNVM7tHN5"
      },
      "source": [
        "## Step 2. EDA 및 데이터 기초 통계 분석\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD18QuastZy8"
      },
      "source": [
        "## Step 3. 모델 학습을 위한 데이터 전처리\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2일차"
      ],
      "metadata": {
        "id": "oeCxHEkArTI-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dev2yLeMta85"
      },
      "source": [
        "### 문제 7. StandardScaler를 이용하여 데이터 전처리하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8P7qVd6yEk3v"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r2rPXtonYq8",
        "outputId": "ea1b75f9-5a85-4b42-a978-34c4e0510e91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n",
              "       'ejection_fraction', 'high_blood_pressure', 'platelets',\n",
              "       'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time',\n",
              "       'DEATH_EVENT'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZUdkt0lEndT"
      },
      "source": [
        "# 수치형 입력 데이터, 범주형 입력 데이터, 출력 데이터로 구분하기\n",
        "X_num = df[['age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','time']]\n",
        "X_cat = df[['anaemia','diabetes','high_blood_pressure','sex','smoking']]\n",
        "y = df[['DEATH_EVENT']]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEkEQeWzuLrY",
        "outputId": "e9d0efe1-3b33-46c6-a4f3-c00c8962ce96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RangeIndex(start=0, stop=299, step=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3EO22NCE3wG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b49e97d7-dba7-469f-832f-20f7ccfd78a3"
      },
      "source": [
        "# 수치형 입력 데이터를 전처리하고 입력 데이터 통합하기\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_num)\n",
        "X_scaled = scaler.transform(X_num)\n",
        "# transform을 통해서 scaled 하게 되면 numpy로 바뀌게 되므로 DataFrame으로 바꿔줘야 한다\n",
        "X_scaled = pd.DataFrame(data=X_scaled,index=X_num.index, columns=X_num.columns)  \n",
        "# index : 행 이름 설정 columns : 열 이름 설정\n",
        "X = pd.concat([X_scaled, X_cat], axis=1)\n",
        "# 수치형 데이터 이후에 concat을 사용해 범주형 데이터를 붙혀주었다\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        age  creatinine_phosphokinase  ejection_fraction     platelets  \\\n",
              "0  1.192945                  0.000166          -1.530560  1.681648e-02   \n",
              "1 -0.491279                  7.514640          -0.007077  7.535660e-09   \n",
              "2  0.350833                 -0.449939          -1.530560 -1.038073e+00   \n",
              "3 -0.912335                 -0.486071          -1.530560 -5.464741e-01   \n",
              "4  0.350833                 -0.435486          -1.530560  6.517986e-01   \n",
              "\n",
              "   serum_creatinine      time  anaemia  diabetes  high_blood_pressure  sex  \\\n",
              "0          0.490057 -1.629502        0         0                    1    1   \n",
              "1         -0.284552 -1.603691        0         0                    0    1   \n",
              "2         -0.090900 -1.590785        0         0                    0    1   \n",
              "3          0.490057 -1.590785        1         0                    0    1   \n",
              "4          1.264666 -1.577879        1         1                    0    0   \n",
              "\n",
              "   smoking  \n",
              "0        0  \n",
              "1        0  \n",
              "2        1  \n",
              "3        0  \n",
              "4        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c85ef77-e9f7-498e-8942-13d9ec1e6f98\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>time</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.192945</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>-1.530560</td>\n",
              "      <td>1.681648e-02</td>\n",
              "      <td>0.490057</td>\n",
              "      <td>-1.629502</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.491279</td>\n",
              "      <td>7.514640</td>\n",
              "      <td>-0.007077</td>\n",
              "      <td>7.535660e-09</td>\n",
              "      <td>-0.284552</td>\n",
              "      <td>-1.603691</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.350833</td>\n",
              "      <td>-0.449939</td>\n",
              "      <td>-1.530560</td>\n",
              "      <td>-1.038073e+00</td>\n",
              "      <td>-0.090900</td>\n",
              "      <td>-1.590785</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.912335</td>\n",
              "      <td>-0.486071</td>\n",
              "      <td>-1.530560</td>\n",
              "      <td>-5.464741e-01</td>\n",
              "      <td>0.490057</td>\n",
              "      <td>-1.590785</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.350833</td>\n",
              "      <td>-0.435486</td>\n",
              "      <td>-1.530560</td>\n",
              "      <td>6.517986e-01</td>\n",
              "      <td>1.264666</td>\n",
              "      <td>-1.577879</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c85ef77-e9f7-498e-8942-13d9ec1e6f98')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c85ef77-e9f7-498e-8942-13d9ec1e6f98 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c85ef77-e9f7-498e-8942-13d9ec1e6f98');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3일차"
      ],
      "metadata": {
        "id": "otrVK8_Wv0xH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x93Tb6lptcA2"
      },
      "source": [
        "### 문제 8. 학습데이터와 테스트데이터 분리하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9kMQI8SEche"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F07QjOFwFNEw"
      },
      "source": [
        "# train_test_split() 함수로 학습 데이터와 테스트 데이터 분리하기\n",
        "# X = 전처리된 전체 데이터 y = 출력 데이터(DEATH_EVENT)\n",
        "# test_size : 테스트 데이터 비율 \n",
        "# stratify : Stratified sampling 무작위로 샘플링을 하는데 기존 데이터셋에서 클래스 비율을 동일하게 유지하면서 분리하는 것 대충 0과 1을 동일한 비율로 train/testset으로 분리해준다는 것 같다.\n",
        "# random_state random함수의 시드값을 고정시켜준다.그래서 shuffle과 같이 사용해서 섞어도 같은 값이 나온다.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=1, shuffle=True)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "B90YQgd5zD93",
        "outputId": "7c9331c7-b177-48da-d513-250f96a09000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          age  creatinine_phosphokinase  ejection_fraction  platelets  \\\n",
              "14  -0.996547                 -0.518074          -0.684180   1.675963   \n",
              "210  0.771889                 -0.381804          -1.784473   1.286781   \n",
              "236  1.192945                 -0.477812           1.008578  -0.157292   \n",
              "44  -0.070223                  0.006360           1.854958  -0.710340   \n",
              "163 -0.912335                  1.808842          -0.260991  -1.929096   \n",
              "..        ...                       ...                ...        ...   \n",
              "203 -0.070223                 -0.539753          -1.107370  -0.525991   \n",
              "255 -0.743913                 -0.403483          -0.684180   0.723490   \n",
              "72   2.035057                  5.471619          -0.260991  -0.208500   \n",
              "235  1.361368                 -0.488136           1.008578   1.460889   \n",
              "37   1.782424                  0.281997           1.008578   0.590349   \n",
              "\n",
              "     serum_creatinine      time  anaemia  diabetes  high_blood_pressure  sex  \\\n",
              "14          -0.381379 -1.526256        1         0                    1    0   \n",
              "210         -0.381379  0.745172        0         1                    1    1   \n",
              "236         -0.284552  1.016195        0         0                    1    1   \n",
              "44          -0.284552 -1.255233        1         1                    0    0   \n",
              "163         -0.478205 -0.054990        1         1                    0    0   \n",
              "..                ...       ...      ...       ...                  ...  ...   \n",
              "203          2.039276  0.732266        0         0                    1    1   \n",
              "255         -0.381379  1.106535        1         1                    1    1   \n",
              "72          -0.381379 -0.751905        0         0                    0    1   \n",
              "235         -0.284552  1.016195        1         0                    1    1   \n",
              "37          -0.381379 -1.293951        1         1                    1    0   \n",
              "\n",
              "     smoking  \n",
              "14         0  \n",
              "210        1  \n",
              "236        0  \n",
              "44         0  \n",
              "163        0  \n",
              "..       ...  \n",
              "203        1  \n",
              "255        1  \n",
              "72         1  \n",
              "235        0  \n",
              "37         0  \n",
              "\n",
              "[209 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5094ea10-e946-45f0-87a8-d0668ffcbf93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>time</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>-0.996547</td>\n",
              "      <td>-0.518074</td>\n",
              "      <td>-0.684180</td>\n",
              "      <td>1.675963</td>\n",
              "      <td>-0.381379</td>\n",
              "      <td>-1.526256</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>0.771889</td>\n",
              "      <td>-0.381804</td>\n",
              "      <td>-1.784473</td>\n",
              "      <td>1.286781</td>\n",
              "      <td>-0.381379</td>\n",
              "      <td>0.745172</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>1.192945</td>\n",
              "      <td>-0.477812</td>\n",
              "      <td>1.008578</td>\n",
              "      <td>-0.157292</td>\n",
              "      <td>-0.284552</td>\n",
              "      <td>1.016195</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>-0.070223</td>\n",
              "      <td>0.006360</td>\n",
              "      <td>1.854958</td>\n",
              "      <td>-0.710340</td>\n",
              "      <td>-0.284552</td>\n",
              "      <td>-1.255233</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>-0.912335</td>\n",
              "      <td>1.808842</td>\n",
              "      <td>-0.260991</td>\n",
              "      <td>-1.929096</td>\n",
              "      <td>-0.478205</td>\n",
              "      <td>-0.054990</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>-0.070223</td>\n",
              "      <td>-0.539753</td>\n",
              "      <td>-1.107370</td>\n",
              "      <td>-0.525991</td>\n",
              "      <td>2.039276</td>\n",
              "      <td>0.732266</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>-0.743913</td>\n",
              "      <td>-0.403483</td>\n",
              "      <td>-0.684180</td>\n",
              "      <td>0.723490</td>\n",
              "      <td>-0.381379</td>\n",
              "      <td>1.106535</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>2.035057</td>\n",
              "      <td>5.471619</td>\n",
              "      <td>-0.260991</td>\n",
              "      <td>-0.208500</td>\n",
              "      <td>-0.381379</td>\n",
              "      <td>-0.751905</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>1.361368</td>\n",
              "      <td>-0.488136</td>\n",
              "      <td>1.008578</td>\n",
              "      <td>1.460889</td>\n",
              "      <td>-0.284552</td>\n",
              "      <td>1.016195</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1.782424</td>\n",
              "      <td>0.281997</td>\n",
              "      <td>1.008578</td>\n",
              "      <td>0.590349</td>\n",
              "      <td>-0.381379</td>\n",
              "      <td>-1.293951</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>209 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5094ea10-e946-45f0-87a8-d0668ffcbf93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5094ea10-e946-45f0-87a8-d0668ffcbf93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5094ea10-e946-45f0-87a8-d0668ffcbf93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTqb-HqPtc4I"
      },
      "source": [
        "## Step 4. Classification 모델 학습하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ckexl202tmZI"
      },
      "source": [
        "### 문제 9. Logistic Regression 모델 생성/학습하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wt_0AdNFfbN"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LogisticRegression(penalty, dual, tol, C, fit_intercept, intercept_scaling, class_weight, random_state, \n",
        "#                    solver, max_iter, multi_class, verbose, warm_start, n_jobs, l1_ratio)\n",
        "# penalty : 규제에 사용 된 기준을 지정 (l1, l2, elasticnet, none) – default : l2\n",
        "# dual : 이중 또는 초기 공식\n",
        "# tol : 정밀도\n",
        "# C : 규제 강도\n",
        "# fit_intercept : 모형에 상수항 (절편)이 있는가 없는가를 결정하는 인수 (default : True)\n",
        "# intercept_scaling : 정규화 효과 정도\n",
        "# class_weight : 클래스의 가중치\n",
        "# random_state : 난수 seed 설정\n",
        "# solver : 최적화 문제에 사용하는 알고리즘\n",
        "# max_iter : 계산에 사용할 작업 수\n",
        "# multi_class : 다중 분류 시에 (ovr, multinomial, auto)로 설정\n",
        "# verbose : 동작 과정에 대한 출력 메시지 verbose=1,2 2로 해주면 1보다 조금 더 많이 보여줌\n",
        "# warm_start : 이전 모델을 초기화로 적합하게 사용할 것인지 여부\n",
        "# n_jobs : 병렬 처리 할 때 사용되는 CPU 코어 수\n",
        "# l1_ratio : L1 규제의 비율(Elastic-Net 믹싱 파라미터 경우에만 사용\n",
        "# https://inuplace.tistory.com/522"
      ],
      "metadata": {
        "id": "mNprdCoj1VUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lM57a_8Fdbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f27fab9b-8e6e-4cc4-8fe0-a84181a4a04b"
      },
      "source": [
        "# LogisticRegression 모델 생성/학습\n",
        "model_lr = LogisticRegression(C=3, max_iter=1000)\n",
        "model_lr.fit(X_train, y_train)\n",
        "\n",
        "model_lr.score(X_train, y_train), model_lr.score(X_test, y_test)\n",
        "#학습 데이터가 테스트 데이터보다 정확도가 높다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8277511961722488, 0.8222222222222222)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APOI7Hc9tnvr"
      },
      "source": [
        "### 문제 10. 모델 학습 결과 평가하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix"
      ],
      "metadata": {
        "id": "ONEjv-XSE2Nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# classification_report\n",
        "# precision 정밀도 : 양성 클래스라고 예측한 샘플 중 실제 양성 클레스에 속하는 샘플 \n",
        "# precision=TP/(TP+FP)\n",
        "# recall 재현율 : 양성 클레스에 속한 샘플 중 양성 클래스라고 예측한 샘플\n",
        "# recall=TP/(TP+FN)\n",
        "# accuracy 정확도 전체 샘플 중 맞게 예측한 샘플 수의 비율\n",
        "# (TP+TN)/(TN+TP+FN+FP)\n",
        "# f1-score precision,recall의 가중 조화평균\n",
        "# 가중치가 1일떄 F1임 \n",
        "# support:샘플 개수\n",
        "#https://blog.naver.com/PostView.naver?blogId=hannaurora&logNo=222498671200&parentCategoryNo=&categoryNo=41&viewDate=&isShowPopularPosts=true&from=search\n"
      ],
      "metadata": {
        "id": "su5IMYdsFcsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lIoyMjFFrif"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dD9JnN-FnpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e4d433-57a3-4195-d481-5be78e2ce2e1"
      },
      "source": [
        "# Predict를 수행하고 classification_report() 결과 출력하기\n",
        "# 학습된 테스트 데이터를 predict() 메서드로 예측\n",
        "pred = model_lr.predict(X_test)\n",
        "# def classification_report(y_true, y_pred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
        "print(classification_report(y_test, pred))\n",
        "# 90개의 데이터를 평가했을 때 82퍼센트의 정확도를 가지고 있음"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.89      0.88        64\n",
            "           1       0.71      0.65      0.68        26\n",
            "\n",
            "    accuracy                           0.82        90\n",
            "   macro avg       0.79      0.77      0.78        90\n",
            "weighted avg       0.82      0.82      0.82        90\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4일차"
      ],
      "metadata": {
        "id": "5o8n2ciWglb4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTRTOLTNto3h"
      },
      "source": [
        "### 문제 11. XGBoost 모델 생성/학습하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow28ZRL4F7D5"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "#def __init__(max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='binary:logistic', booster='gbtree',\n",
        "# n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1,\n",
        "# reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, **kwargs)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "- General Parameters ( XGBoost 의 어떤 모델을 쓸거야? )\n",
        "\n",
        "    booster='gbtree' # 트리,회귀(gblinear) 트리가 항상 # 더 좋은 성능을 내기 때문에 수정할 필요없다고한다.\n",
        "            # gblinear : 선형 모델        \n",
        "    \n",
        "    silent=True  # running message출력안한다.\n",
        "                 # 모델이 적합되는 과정을 이해하기위해선 False으로한다.\n",
        "\n",
        "    nthread =4    # XGBoost를 실행하기 위한 병렬처리(쓰레드)\n",
        "                  #갯수. 'n_jobs' 를 사용해라.\n",
        "\n",
        "- Booster Parameters ( 모델의 조건 설정 )\n",
        "\n",
        "    n_estimators [default = 100] : 나무의 개수\n",
        "\n",
        "    early_stopping_rounds \n",
        "        최대한 몇 개의 트리를 완성해볼 것인지 \n",
        "        valid loss에 더이상 진전이 없으면 멈춤\n",
        "        과적합을 방지할 수 있음, n_estimators 가 높을때 주로 사용.\n",
        "\n",
        "    learning_rate [default = 0.1] (=eta [default = 0.3] : 파이썬 래퍼에서 적용)\n",
        "        학습 단계별로 가중치를 얼만큼 사용할지 결정/ 이전의 결과를 얼마나 반영할건지\n",
        "        낮은 eta -> 낮은 가중치 -> 다음 단계의 결과물 적게 반영 -> 보수적\n",
        "        일반적으로 0.01 ~ 0.2\n",
        "        높은 값으로 다른 파라미터 조절하여 결정한 후, 낮춰서 최적의 파라미 결정\n",
        "        * gradient boost에서는 기울기의 의미, 작으면 꼼꼼히 내려가고 크면 급하게 내려감\n",
        "\n",
        "     min_child_weight [default = 1]\n",
        "        child 에서 필요한 모든 관측치에 대한 가중치의 최소 합\n",
        "        이 값보다 샘플 수가 작으면 leaf node가 되는 것\n",
        "        너무 크면 under-fitting 될 수 있음 (training이 되지 못한 과소적합상태)\n",
        "        CV로 조절해야함\n",
        "\n",
        "    max_depth [default = 6]\n",
        "        트리의 최대 깊이\n",
        "        일반적으로 3 ~ 10  \n",
        "        CV로 조절해야함\n",
        "    \n",
        "    gamma =0    # 노드가 split 되기 위한 loss function의 값이\n",
        "                # 감소하는 최소값을 정의한다. gamma 값이 높아질 수록 \n",
        "                # 알고리즘은 보수적으로 변하고, loss function의 정의\n",
        "                # 에 따라 적정값이 달라지기때문에 반드시 튜닝.\n",
        "                 트리에서 추가적으로 가지를 나눌지를 결정할 최소 손실 감소 값\n",
        "                 값이 클수록 과적합 감소 효과\n",
        "     \n",
        "    subsample [default = 1] (=sub_sample : 파이썬 래퍼에서 적용)\n",
        "        각 트리마다 데이터 샘플링 비율\n",
        "        over-fitting 방지\n",
        "        일반적으로 0.5 ~ 1     \n",
        "    \n",
        "    colsample_bytree=0.8   # 트리를 생성할때 훈련 데이터에서 \n",
        "                           # 변수를 샘플링해주는 비율. 보통0.6~0.9\n",
        "\n",
        "    reg_lambda [default = 1] (=lambda : 파이썬 래퍼에서 적용)\n",
        "        L2 regularization(ex. 릿지) 가중치\n",
        "        클수록 보수적\n",
        "        가중치에 l2적용 값\n",
        "\n",
        "    reg_alpha [default = 0] (=alpha : 파이썬 래퍼에서 적용)\n",
        "        L1 regularization(ex. 라쏘) 가중치\n",
        "        클수록 보수적\n",
        "        특성이 매우 많은때 사용해볼만 함\n",
        "        가중치에 l1규제 적용 값인듯\n",
        "\n",
        "    scale_pos_weight [default = 1]\n",
        "        데이터가 불균형할때 사용, 0보다 큰 값\n",
        "        보통 값을 음성 데이터 수/ 양성 데이터 수 값으로 함\n",
        "        잘못 분류할 때 패널티를 부과해서 양성과 음성비율을 비슷하게 맞추는 용도인듯\n",
        "\n",
        "    \n",
        "    objective = 'reg:linear','binary:logistic','multi:softmax',\n",
        "                'multi:softprob'  # 4가지 존재.\n",
        "            # 회귀 경우 'reg', binary분류의 경우 'binary',\n",
        "            # 다중분류경우 'multi'- 분류된 class를 return하는 경우 'softmax'\n",
        "            # 각 class에 속할 확률을 return하는 경우 'softprob'\n",
        "    objective [default = reg:linear] (목적 함수)\n",
        "        binary:logistic :이진 분류를 위한 로지스틱 회귀, 클래스가 아닌 예측된 확률 반환\n",
        "        multi:softmax : softmax를 사용한 다중 클래스 분류, 확률이 아닌 예측된 클래스 반환\n",
        "        multi:softprob : softmax와 같지만 각 클래스에 대한 예상 확률 반환\n",
        "    \n",
        "     eval_metric [목적 함수에 따라 디폴트 값이 다름(회귀-rmse / 분류-error)]\n",
        "\n",
        "        rmse : root mean square error\n",
        "        mae : mean absolute error\n",
        "        logloss : negative log-likelihood\n",
        "        error : binary classificaion error rate (임계값 0.5)\n",
        "        merror : multiclass classification error rate\n",
        "        mlogloss : multiclass logloss\n",
        "        auc : area under the curve\n",
        "\n",
        "    random_state =  # random number seed.\n",
        "                    # seed 와 동일.\n",
        ")\n",
        "https://blog.naver.com/PostView.nhn?blogId=gustn3964&logNo=221431714122&from=search&redirect=Log&widgetTypeCall=true&directAccess=false #파이썬 Scikit-Learn형식 XGBoost 파라미터\n",
        "https://hwi-doc.tistory.com/entry/%EC%9D%B4%ED%95%B4%ED%95%98%EA%B3%A0-%EC%82%AC%EC%9A%A9%ED%95%98%EC%9E%90-XGBoost # XGBoost 이해하고 사용하자\n",
        "https://nobsai.tistory.com/53 # XGBoost 간단 사용 가이드\n",
        "'''"
      ],
      "metadata": {
        "id": "DwEAQuTChmtX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "7d499136-c91c-450c-af18-bc2bcf8de888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n- General Parameters ( XGBoost 의 어떤 모델을 쓸거야? )\\n\\n    booster='gbtree' # 트리,회귀(gblinear) 트리가 항상 # 더 좋은 성능을 내기 때문에 수정할 필요없다고한다.\\n            # gblinear : 선형 모델        \\n    \\n    silent=True  # running message출력안한다.\\n                 # 모델이 적합되는 과정을 이해하기위해선 False으로한다.\\n\\n    nthread =4    # XGBoost를 실행하기 위한 병렬처리(쓰레드)\\n                  #갯수. 'n_jobs' 를 사용해라.\\n\\n- Booster Parameters ( 모델의 조건 설정 )\\n\\n    n_estimators [default = 100] : 나무의 개수\\n\\n    early_stopping_rounds \\n        최대한 몇 개의 트리를 완성해볼 것인지 \\n        valid loss에 더이상 진전이 없으면 멈춤\\n        과적합을 방지할 수 있음, n_estimators 가 높을때 주로 사용.\\n\\n    learning_rate [default = 0.1] (=eta [default = 0.3] : 파이썬 래퍼에서 적용)\\n        학습 단계별로 가중치를 얼만큼 사용할지 결정/ 이전의 결과를 얼마나 반영할건지\\n        낮은 eta -> 낮은 가중치 -> 다음 단계의 결과물 적게 반영 -> 보수적\\n        일반적으로 0.01 ~ 0.2\\n        높은 값으로 다른 파라미터 조절하여 결정한 후, 낮춰서 최적의 파라미 결정\\n        * gradient boost에서는 기울기의 의미, 작으면 꼼꼼히 내려가고 크면 급하게 내려감\\n\\n     min_child_weight [default = 1]\\n        child 에서 필요한 모든 관측치에 대한 가중치의 최소 합\\n        이 값보다 샘플 수가 작으면 leaf node가 되는 것\\n        너무 크면 under-fitting 될 수 있음 (training이 되지 못한 과소적합상태)\\n        CV로 조절해야함\\n\\n    max_depth [default = 6]\\n        트리의 최대 깊이\\n        일반적으로 3 ~ 10  \\n        CV로 조절해야함\\n    \\n    gamma =0    # 노드가 split 되기 위한 loss function의 값이\\n                # 감소하는 최소값을 정의한다. gamma 값이 높아질 수록 \\n                # 알고리즘은 보수적으로 변하고, loss function의 정의\\n                # 에 따라 적정값이 달라지기때문에 반드시 튜닝.\\n                 트리에서 추가적으로 가지를 나눌지를 결정할 최소 손실 감소 값\\n                 값이 클수록 과적합 감소 효과\\n     \\n    subsample [default = 1] (=sub_sample : 파이썬 래퍼에서 적용)\\n        각 트리마다 데이터 샘플링 비율\\n        over-fitting 방지\\n        일반적으로 0.5 ~ 1     \\n    \\n    colsample_bytree=0.8   # 트리를 생성할때 훈련 데이터에서 \\n                           # 변수를 샘플링해주는 비율. 보통0.6~0.9\\n\\n    reg_lambda [default = 1] (=lambda : 파이썬 래퍼에서 적용)\\n        L2 regularization(ex. 릿지) 가중치\\n        클수록 보수적\\n        가중치에 l2적용 값\\n\\n    reg_alpha [default = 0] (=alpha : 파이썬 래퍼에서 적용)\\n        L1 regularization(ex. 라쏘) 가중치\\n        클수록 보수적\\n        특성이 매우 많은때 사용해볼만 함\\n        가중치에 l1규제 적용 값인듯\\n\\n    scale_pos_weight [default = 1]\\n        데이터가 불균형할때 사용, 0보다 큰 값\\n        보통 값을 음성 데이터 수/ 양성 데이터 수 값으로 함\\n        잘못 분류할 때 패널티를 부과해서 양성과 음성비율을 비슷하게 맞추는 용도인듯\\n\\n    \\n    objective = 'reg:linear','binary:logistic','multi:softmax',\\n                'multi:softprob'  # 4가지 존재.\\n            # 회귀 경우 'reg', binary분류의 경우 'binary',\\n            # 다중분류경우 'multi'- 분류된 class를 return하는 경우 'softmax'\\n            # 각 class에 속할 확률을 return하는 경우 'softprob'\\n    objective [default = reg:linear] (목적 함수)\\n        binary:logistic :이진 분류를 위한 로지스틱 회귀, 클래스가 아닌 예측된 확률 반환\\n        multi:softmax : softmax를 사용한 다중 클래스 분류, 확률이 아닌 예측된 클래스 반환\\n        multi:softprob : softmax와 같지만 각 클래스에 대한 예상 확률 반환\\n    \\n     eval_metric [목적 함수에 따라 디폴트 값이 다름(회귀-rmse / 분류-error)]\\n\\n        rmse : root mean square error\\n        mae : mean absolute error\\n        logloss : negative log-likelihood\\n        error : binary classificaion error rate (임계값 0.5)\\n        merror : multiclass classification error rate\\n        mlogloss : multiclass logloss\\n        auc : area under the curve\\n\\n    random_state =  # random number seed.\\n                    # seed 와 동일.\\n)\\nhttps://blog.naver.com/PostView.nhn?blogId=gustn3964&logNo=221431714122&from=search&redirect=Log&widgetTypeCall=true&directAccess=false #파이썬 Scikit-Learn형식 XGBoost 파라미터\\nhttps://hwi-doc.tistory.com/entry/%EC%9D%B4%ED%95%B4%ED%95%98%EA%B3%A0-%EC%82%AC%EC%9A%A9%ED%95%98%EC%9E%90-XGBoost # XGBoost 이해하고 사용하자\\nhttps://nobsai.tistory.com/53 # XGBoost 간단 사용 가이드\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSSNqFUrGM6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107712e3-1e7e-4799-c6df-557937acf3d1"
      },
      "source": [
        "# XGBClassifier 모델 생성/학습\n",
        "# 로지스틱이고 분류 모형이다.\n",
        "model_xgb = XGBClassifier()#(objective='binary:logistic')\n",
        "model_xgb.fit(X_train,y_train)#(X_train,y_train,early_stopping_rounds=10,eval_metric='error',eval_set=[(X_test, y_test)])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAisZoSEtp35"
      },
      "source": [
        "### 문제 12. 모델 학습 결과 평가하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLnyYNJwGRgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f12d1ddf-c5ea-4466-9bae-5cc3b6835e9f"
      },
      "source": [
        "# Predict를 수행하고 classification_report() 결과 출력하기\n",
        "pred_xgb = model_xgb.predict(X_test)\n",
        "print(classification_report(y_test, pred_xgb))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.89      0.86        64\n",
            "           1       0.68      0.58      0.62        26\n",
            "\n",
            "    accuracy                           0.80        90\n",
            "   macro avg       0.76      0.73      0.74        90\n",
            "weighted avg       0.79      0.80      0.79        90\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A7Ghq67tqsM"
      },
      "source": [
        "### 문제 13. 특징의 중요도 확인하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fo6x7b7GU1W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "57b17a32-621e-49f7-d4fc-0642a18a61b7"
      },
      "source": [
        "# XGBClassifier 모델의 feature_importances_를 이용하여 중요도 plot\n",
        "plt.bar(X.columns, model_xgb.feature_importances_)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
